{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Laatr1c6lr1w"
   },
   "outputs": [],
   "source": [
    "!wget -O cat1.jpg https://storage.googleapis.com/laurencemoroney-blog.appspot.com/MLColabImages/cat1.jpg\n",
    "!wget -O cat2.jpg https://storage.googleapis.com/laurencemoroney-blog.appspot.com/MLColabImages/cat2.jpg\n",
    "!wget -O catanddog.jpg https://storage.googleapis.com/laurencemoroney-blog.appspot.com/MLColabImages/catanddog.jpg\n",
    "!wget -O dog1.jpg https://storage.googleapis.com/laurencemoroney-blog.appspot.com/MLColabImages/dog1.jpg\n",
    "!wget -O dog2.jpg https://storage.googleapis.com/laurencemoroney-blog.appspot.com/MLColabImages/dog2.jpg\n",
    "\n",
    "# Download prepared weights\n",
    "!wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=1kipXTxesGJKGY1B8uSPRvxROgOH90fih' -O 0_epochs.h5\n",
    "!wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=1oiV6tjy5k7h9OHGTQaf0Ohn3FmF-uOs1' -O 15_epochs.h5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X86LKLvpBO2S"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "#from keras.utils import plot_model\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Conv2D, Flatten, MaxPooling2D, GlobalAveragePooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7w5HNdoHBQv_"
   },
   "outputs": [],
   "source": [
    "train_data = tfds.load('cats_vs_dogs', split='train[:80%]', as_supervised=True)\n",
    "validation_data = tfds.load('cats_vs_dogs', split='train[80%:90%]', as_supervised=True)\n",
    "test_data = tfds.load('cats_vs_dogs', split='train[-10%:]', as_supervised=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pRkrL2aK2_UZ"
   },
   "outputs": [],
   "source": [
    "def augmentimages(image, label):\n",
    "\n",
    "  # cast to float\n",
    "  image = tf.cast(image, tf.float32)\n",
    "  # normalize the pixel values\n",
    "  image = (image/255)\n",
    "  # resize to 300 x 300\n",
    "  image = tf.image.resize(image,(300,300))\n",
    "\n",
    "  label = tf.one_hot(label, 2)\n",
    "  \n",
    "  return image, label\n",
    "\n",
    "  return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vpNEfDKM353a"
   },
   "outputs": [],
   "source": [
    "augmented_training_data = train_data.map(augmentimages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "POhDDPBY3vnL"
   },
   "outputs": [],
   "source": [
    "train_batches = augmented_training_data.batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IoyCA80GBSlG"
   },
   "outputs": [],
   "source": [
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(16,input_shape=(300,300,3),kernel_size=(3,3),activation='relu',padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(32,kernel_size=(3,3),activation='relu',padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(64,kernel_size=(3,3),activation='relu',padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(128,kernel_size=(3,3),activation='relu',padding='same'))\n",
    "model.add(GlobalAveragePooling2D())\n",
    "model.add(Dense(2,activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sKbvh3bl9vnG"
   },
   "outputs": [],
   "source": [
    "def do_salience(image, model, label, prefix):\n",
    "  '''\n",
    "  Generates the saliency map of a given image.\n",
    "\n",
    "  Args:\n",
    "    image (file) -- picture that the model will classify\n",
    "    model (keras Model) -- your cats and dogs classifier\n",
    "    label (int) -- ground truth label of the image\n",
    "    prefix (string) -- prefix to add to the filename of the saliency map\n",
    "  '''\n",
    "\n",
    "  # Read the image and convert channel order from BGR to RGB\n",
    "  img = cv2.imread(image)\n",
    "  img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) \n",
    "  # Resize the image to 300 x 300 and normalize pixel values to the range [0, 1]\n",
    "  img = cv2.resize(img, (300, 300)) / 255.0\n",
    "\n",
    "  # Add an additional dimension (for the batch), and save this in a new variable\n",
    "  img2 = np.expand_dims(img, axis=0)\n",
    "\n",
    "  # Declare the number of classes\n",
    "  num_classes = 2\n",
    "\n",
    "  # Define the expected output array by one-hot encoding the label\n",
    "  # The length of the array is equal to the number of classes\n",
    "  expected_output = tf.one_hot([label] * img2.shape[0], num_classes)\n",
    "\n",
    "\n",
    "  with tf.GradientTape() as tape:\n",
    "    inputs = tf.cast(img2, tf.float32)\n",
    "    tape.watch(inputs)\n",
    "    predictions = model(inputs)\n",
    "    loss = tf.keras.losses.categorical_crossentropy(\n",
    "        expected_output, predictions\n",
    "    )\n",
    "\n",
    "  # get the gradients of the loss with respect to the model's input image\n",
    "  gradients = tape.gradient(loss, inputs)\n",
    "    \n",
    "  # generate the grayscale tensor\n",
    "  grayscale_tensor = tf.reduce_sum(tf.abs(gradients), axis=-1)\n",
    "\n",
    "  # normalize the pixel values to be in the range [0, 255].\n",
    "  # the max value in the grayscale tensor will be pushed to 255.\n",
    "  # the min value will be pushed to 0.\n",
    "  normalized_tensor = tf.cast(\n",
    "    255\n",
    "    * (grayscale_tensor - tf.reduce_min(grayscale_tensor))\n",
    "    / (tf.reduce_max(grayscale_tensor) - tf.reduce_min(grayscale_tensor)),\n",
    "    tf.uint8\n",
    "  )\n",
    "    \n",
    "  # Remove dimensions that are size 1\n",
    "  normalized_tensor = tf.squeeze(normalized_tensor)\n",
    "    \n",
    "\n",
    "  plt.figure(figsize=(8, 8))\n",
    "  plt.axis('off')\n",
    "  plt.imshow(normalized_tensor, cmap='gray')\n",
    "  plt.show()\n",
    "\n",
    "  gradient_color = cv2.applyColorMap(normalized_tensor.numpy(), cv2.COLORMAP_HOT)\n",
    "  gradient_color = gradient_color / 255.0\n",
    "  super_imposed = cv2.addWeighted(img, 0.5, gradient_color, 0.5, 0.0)\n",
    "\n",
    "  salient_image_name = prefix + image\n",
    "  normalized_tensor = tf.expand_dims(normalized_tensor, -1)\n",
    "  normalized_tensor = tf.io.encode_jpeg(normalized_tensor, quality=100, format='grayscale')\n",
    "  writer = tf.io.write_file(salient_image_name, normalized_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k39fF4n8fgG0"
   },
   "outputs": [],
   "source": [
    "# load initial weights\n",
    "model.load_weights('0_epochs.h5')\n",
    "\n",
    "# generate the saliency maps for the 5 test images\n",
    "do_salience('cat1.jpg', model, 0, 'epoch0_salient')\n",
    "do_salience('cat2.jpg', model, 0, 'epoch0_salient')\n",
    "do_salience('catanddog.jpg', model, 0, 'epoch0_salient')\n",
    "do_salience('dog1.jpg', model, 1, 'epoch0_salient')\n",
    "do_salience('dog2.jpg', model, 1, 'epoch0_salient')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DkyWZ5KdBo-z"
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer=tf.keras.optimizers.RMSprop(lr=0.001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5YSNp7k7BqfL"
   },
   "outputs": [],
   "source": [
    "# load pre-trained weights\n",
    "model.load_weights('15_epochs.h5')\n",
    "\n",
    "# train the model for just 3 epochs\n",
    "model.fit(train_batches, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bXFtabyVhIKN"
   },
   "outputs": [],
   "source": [
    "do_salience('cat1.jpg', model, 0, 'salient')\n",
    "do_salience('cat2.jpg', model, 0, 'salient')\n",
    "do_salience('catanddog.jpg', model, 0, 'salient')\n",
    "do_salience('dog1.jpg', model, 1, 'salient')\n",
    "do_salience('dog2.jpg', model, 1, 'salient')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b-MhcA8Uh8H_"
   },
   "outputs": [],
   "source": [
    "from zipfile import ZipFile\n",
    "\n",
    "!rm images.zip\n",
    "\n",
    "filenames = ['cat1.jpg', 'cat2.jpg', 'catanddog.jpg', 'dog1.jpg', 'dog2.jpg']\n",
    "\n",
    "# writing files to a zipfile \n",
    "with ZipFile('images.zip','w') as zip:\n",
    "  for file in filenames:\n",
    "    zip.write('salient' + file)\n",
    "\n",
    "print(\"images.zip generated!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "elUfhSmMvJZh"
   },
   "outputs": [],
   "source": [
    "!wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=14vFpBJsL_TNQeugX8vUTv8dYZxn__fQY' -O 95_epochs.h5\n",
    "\n",
    "model.load_weights('95_epochs.h5')\n",
    "\n",
    "do_salience('cat1.jpg', model, 0, \"epoch95_salient\")\n",
    "do_salience('cat2.jpg', model, 0, \"epoch95_salient\")\n",
    "do_salience('catanddog.jpg', model, 0, \"epoch95_salient\")\n",
    "do_salience('dog1.jpg', model, 1, \"epoch95_salient\")\n",
    "do_salience('dog2.jpg', model, 1, \"epoch95_salient\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of C3W4_Assignment.ipynb",
   "private_outputs": true,
   "provenance": [
    {
     "file_id": "17PtVJuaX6EZBi3GBIvs6X6I5mnx-xIFd",
     "timestamp": 1622773642244
    }
   ],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
